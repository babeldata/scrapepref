# Guide de contribution

Merci de votre int√©r√™t pour contribuer √† ce projet ! Ce document fournit des directives pour contribuer au scraper des arr√™t√©s de la pr√©fecture de police.

## üöÄ D√©marrage rapide

1. Fork le repository
2. Clone votre fork : `git clone https://github.com/votre-username/scrapepref.git`
3. Cr√©ez une branche : `git checkout -b feature/ma-fonctionnalite`
4. Installez les d√©pendances : `uv pip install -r requirements.txt && playwright install chromium`
5. Testez vos modifications : `python run_local.py`

## üìù Processus de contribution

### 1. Signaler un bug

Si vous trouvez un bug, ouvrez une issue avec :
- Description claire du probl√®me
- √âtapes pour reproduire
- Comportement attendu vs comportement actuel
- Version de Python et OS
- Logs pertinents (si disponibles)

### 2. Proposer une am√©lioration

Pour proposer une nouvelle fonctionnalit√© :
- Ouvrez une issue pour discuter de l'id√©e
- D√©crivez le cas d'usage et les b√©n√©fices
- Attendez la validation avant de coder

### 3. Soumettre une Pull Request

1. **Assurez-vous que votre code fonctionne** :
   ```bash
   python run_local.py  # Test en mode DRY_RUN
   ```

2. **Suivez les conventions de code** :
   - Utilisez des noms de variables explicites
   - Ajoutez des docstrings aux fonctions
   - Commentez les parties complexes
   - Respectez PEP 8 (formatage Python)

3. **Testez vos modifications** :
   - V√©rifiez que le scraper fonctionne avec `run_local.py`
   - Testez la classification des arr√™t√©s
   - V√©rifiez l'upload S3 (en mode DRY_RUN)

4. **Documentez vos changements** :
   - Mettez √† jour le README si n√©cessaire
   - Ajoutez des commentaires dans le code
   - Documentez les nouvelles variables d'environnement

5. **Soumettez la PR** :
   - Titre clair et descriptif
   - Description d√©taill√©e des changements
   - R√©f√©rencez les issues li√©es (ex: "Fixes #123")

## üîç Zones de contribution

### Am√©lioration de la classification

La fonction `is_circulation_arrete()` dans `src/scraper.py` peut √™tre am√©lior√©e :
- Ajouter de nouveaux mots-cl√©s
- Am√©liorer les patterns regex
- Utiliser du NLP pour une meilleure pr√©cision

### Extraction de donn√©es

La fonction `extract_arrete_info()` peut √™tre adapt√©e si la structure HTML du site change :
- Adapter les s√©lecteurs CSS
- Extraire de nouvelles m√©tadonn√©es
- G√©rer de nouveaux formats de dates

### Performance

Optimisations possibles :
- Parall√©lisation am√©lior√©e
- Cache des pages d√©j√† scrap√©es
- Gestion plus efficace de la m√©moire

### Tests

Ajout de tests unitaires et d'int√©gration :
- Tests de classification
- Tests d'extraction HTML
- Tests d'upload S3 (mock)

## üìã Checklist avant de soumettre

- [ ] Code test√© localement
- [ ] Pas d'erreurs de linting
- [ ] Documentation mise √† jour
- [ ] Variables d'environnement document√©es
- [ ] Messages de commit clairs
- [ ] PR li√©e √† une issue (si applicable)

## üéØ Priorit√©s actuelles

1. **Am√©lioration de la classification** : R√©duire les faux positifs/n√©gatifs
2. **Robustesse** : G√©rer les changements de structure HTML
3. **Performance** : Optimiser le temps de scraping
4. **Tests** : Ajouter une suite de tests compl√®te

## üí¨ Questions ?

N'h√©sitez pas √† ouvrir une issue pour poser des questions ou discuter d'id√©es avant de commencer √† coder !

